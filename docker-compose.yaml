version: "3.7"
services:

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    ports:
      - '32181:32181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000
    extra_hosts:
      - "moby:127.0.0.1"

  kafka:
    image: confluentinc/cp-kafka:latest
    ports:
      - '2181:2181'
      - '29092:29092'
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    extra_hosts:
      - "moby:127.0.0.1"

  kafkadrop:
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports:
      - '9000:9000'
    depends_on:
      - kafka
      - zookeeper
    environment:
      KAFKA_BROKERCONNECT: kafka:9092
      JVM_OPTS: -Xms32M -Xmx64M
    extra_hosts:
      - "moby:127.0.0.1"
  postgres:
    image: postgres:11.3
    environment:
      POSTGRES_USERNAME: postgres
      POSTGRES_PASSWORD: postgres1234
      POSTGRES_DB: demo
    ports:
    - "5432:5432/tcp"
    networks:
    - pyspark-net
    volumes:
    - $HOME/data/postgres:/var/lib/postgresql/data
    deploy:
     restart_policy:
       condition: on-failure
  adminer:
    image: adminer:latest
    ports:
    - "8080:8080/tcp"
    networks:
    - pyspark-net
    deploy:
     restart_policy:
       condition: on-failure

networks:
  pyspark-net: